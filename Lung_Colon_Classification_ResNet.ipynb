{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "333cd369-5fc0-47bf-b85a-8f12eb27529f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7802339-bf84-4f21-950f-cc22cde79a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-2.11.0.dev20251215-cp313-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchvision-0.25.0.dev20251215-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.10.0.dev20251215-cp313-cp313-macosx_12_0_arm64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/nightly/cpu/torch-2.11.0.dev20251215-cp313-none-macosx_11_0_arm64.whl (78.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cpu/torchvision-0.25.0.dev20251215-cp313-cp313-macosx_12_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.10.0.dev20251215-cp313-cp313-macosx_12_0_arm64.whl (737 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.5/737.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [torchaudio]3\u001b[0m [torchvision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch-2.11.0.dev20251215 torchaudio-2.10.0.dev20251215 torchvision-0.25.0.dev20251215\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3484a5ee-548d-4a24-bc97-1d5b3a58ce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "MPS available: True\n",
      "MPS built: True\n",
      "MPS works!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.randn(1000, 1000, device=mps_device)\n",
    "    y = x @ x\n",
    "    print(\"MPS works!\")\n",
    "else:\n",
    "    print(\"MPS not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b536fc3-496b-4698-9b79-6470b6ccc718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-1.0.22-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (from timm) (2.11.0.dev20251215)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.13/site-packages (from timm) (0.25.0.dev20251215)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.13/site-packages (from timm) (6.0.3)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (2025.10.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub->timm)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: shellingham in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Collecting typer-slim (from huggingface_hub->timm)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.10.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch->timm) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch->timm) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision->timm) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision->timm) (12.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer-slim->huggingface_hub->timm) (8.2.1)\n",
      "Downloading timm-1.0.22-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: typer-slim, safetensors, hf-xet, huggingface_hub, timm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [timm][32m4/5\u001b[0m [timm]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.2.0 huggingface_hub-1.2.3 safetensors-0.7.0 timm-1.0.22 typer-slim-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b65bbb1-7e51-4e6f-9b5f-4d58892b8881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46049c69-fe20-4ae0-98bb-35e9e2ce866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d271737b-1548-4cbb-b296-d27681811278",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.mps.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "647c011e-933b-4b01-a25c-cd8a4ceb127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting primary compute as gpu\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4589683-5dca-4f08-bb30-67a770c3c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "base_dir = \"Downloads/lung_colon_image_set\"\n",
    "sources = [\"colon_image_sets\", \"lung_image_sets\"]\n",
    "\n",
    "for src in sources:\n",
    "    src_path = os.path.join(base_dir, src)\n",
    "    for item in os.listdir(src_path):\n",
    "        item_path = os.path.join(src_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            shutil.move(item_path, base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a300f54-c04f-4c00-9178-60917b8f82a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd2277a6-682d-41f6-85c2-5cb7f085dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lung_aca',\n",
       " 'colon_n',\n",
       " 'lung_image_sets',\n",
       " 'colon_aca',\n",
       " 'colon_image_sets',\n",
       " 'lung_n',\n",
       " 'lung_scc']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Downloads/lung_colon_image_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "140b9a5a-8989-4f66-9ee7-9dce3e9807e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lc25000Data(Dataset):\n",
    "    def __init__(self, dir, transform = None):\n",
    "\n",
    "        self.dir = Path(dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.classes = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\n",
    "\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.dir / class_name\n",
    "            if class_dir.exists():\n",
    "                for img_path in class_dir.glob('*.jpeg'):\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(self.class_to_idx[class_name])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "efb2eea8-0c6c-40a9-b2c4-50afd6dd2e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining image transformations\n",
    "\n",
    "# mean and std values are taken for ImageNet - can be changed for other models\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale = (0.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomRotation(degrees = 15),\n",
    "    transforms.ColorJitter(brightness =  0.2, contrast = 0.2, saturation = 0.2, hue = 0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6d52e42c-d6b8-47fd-8635-2ac51c7dc07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path(\"Downloads/lung_colon_image_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "553f94b8-4caa-4f50-8651-d03a48baa538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Lc25000Data(data, transform = train_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68dbe27d-a392-4018-9ff4-fcfcff185aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ed693fa-987b-4c51-81de-1d2d268b0e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 20000\n",
      "Validation samples: 5000\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(train_dataset)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = total_samples - train_size\n",
    "\n",
    "indices = torch.randperm(total_samples).tolist()\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "print(f\"Training samples: {len(train_indices)}\")\n",
    "print(f\"Validation samples: {len(val_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa0a3c3f-7769-4d7b-b0ef-076e4672c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(train_dataset, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "07f5a4cb-a786-4ede-9024-567c77fc965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=\n",
    "                        num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aa579432-b0b5-4736-8b87-10c5644796e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Model Implementation\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, pretrained = True):\n",
    "        super(ResNetModel, self).__init__()\n",
    "\n",
    "        if pretrained:\n",
    "            weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "            self.backbone = torchvision.models.resnet50(weights=weights)\n",
    "\n",
    "        else:\n",
    "            self.backbone = torchvision.models.resnet50(weights=None)\n",
    "\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.backbone.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4296fa13-87cf-48b9-a8ca-c732b6b5d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /Users/sharathsr/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 97.8M/97.8M [00:15<00:00, 6.79MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNetModel(num_classes = 5, pretrained = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "18d1b471-f4c4-4533-a180-5b1c7755e1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res net\n",
      "total parameters: 23518277\n"
     ]
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"res net\")\n",
    "print(f\"total parameters: {count_params(resnet_model)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "57a8f955-fd6b-47fa-8c5c-9682effd4669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs = 25, lr = 1e-4, patience = 7):\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                     factor=0.5, patience=3)\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    best_model_state = None\n",
    "\n",
    "    is_parallel = isinstance(model, nn.DataParallel)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Train]')\n",
    "\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_pbar):\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            var1, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "                'Acc': f'{100.*correct_preds/total_samples:.2f}%'\n",
    "            })\n",
    "\n",
    "\n",
    "        train_loss = running_loss/len(train_loader)\n",
    "        train_acc = correct_preds / total_samples\n",
    "\n",
    "\n",
    "        # Validation\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc = f'Epoch {epoch + 1}/{num_epochs} [Val]')\n",
    "\n",
    "            for images, labels in val_pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                var1, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{val_loss/len(val_loader):.4f}',\n",
    "                    'Acc': f'{100.*correct/total:.2f}%'\n",
    "                })\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        print(f'  Learning Rate: {new_lr:.2e}')\n",
    "\n",
    "        if val_acc > 0.99:\n",
    "            print(\"Very high validation accuracy - possible overfitting!\")\n",
    "        if val_loss < 0.01:\n",
    "            print(\"Very low validation loss - possible data leakage!\")\n",
    "        if len(val_accuracies) > 1 and val_acc < val_accuracies[-2] - 0.05:\n",
    "            print(\"Validation accuracy dropped significantly!\")\n",
    "\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            \n",
    "            best_model_state = model.module.state_dict().copy() if is_parallel else model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f'New best validation accuracy: {best_val_acc:.4f}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "\n",
    "        \n",
    "    if best_model_state is not None:\n",
    "        if is_parallel:\n",
    "            model.module.load_state_dict(best_model_state)\n",
    "        else:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        print(f'Loaded best model with validation accuracy: {best_val_acc:.4f}')\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "85007f26-b0a3-40c1-874f-09b4dc1b881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, history, model_name, save_dir = \"models\"):\n",
    "    os.makedirs(save_dir, exist_ok = True)\n",
    "\n",
    "    model_path = os.path.join(save_dir, f\"{model_name}_model.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    \n",
    "\n",
    "    return model_path\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "04717013-fc86-449c-add1-cd6014dbf5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ResNet Training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|█| 625/625 [08:39<00:00,  1.20it/s, Loss=0.1944, Acc=93\n",
      "Epoch 1/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.64it/s, Loss=0.0327, Acc=99.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 0.1944, Train Acc: 0.9369\n",
      "  Val Loss: 0.0327, Val Acc: 0.9904\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n",
      "New best validation accuracy: 0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|█| 625/625 [08:42<00:00,  1.20it/s, Loss=0.0476, Acc=98\n",
      "Epoch 2/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.62it/s, Loss=0.0179, Acc=99.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 0.0476, Train Acc: 0.9841\n",
      "  Val Loss: 0.0179, Val Acc: 0.9950\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n",
      "New best validation accuracy: 0.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|█| 625/625 [08:43<00:00,  1.19it/s, Loss=0.0322, Acc=98\n",
      "Epoch 3/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.64it/s, Loss=0.0169, Acc=99.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 0.0322, Train Acc: 0.9899\n",
      "  Val Loss: 0.0169, Val Acc: 0.9936\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|█| 625/625 [08:39<00:00,  1.20it/s, Loss=0.0233, Acc=99\n",
      "Epoch 4/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.63it/s, Loss=0.0203, Acc=99.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 0.0233, Train Acc: 0.9932\n",
      "  Val Loss: 0.0203, Val Acc: 0.9948\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|█| 625/625 [08:39<00:00,  1.20it/s, Loss=0.0187, Acc=99\n",
      "Epoch 5/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.64it/s, Loss=0.0103, Acc=99.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 0.0187, Train Acc: 0.9947\n",
      "  Val Loss: 0.0103, Val Acc: 0.9970\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n",
      "New best validation accuracy: 0.9970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|█| 625/625 [08:40<00:00,  1.20it/s, Loss=0.0179, Acc=99\n",
      "Epoch 6/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.63it/s, Loss=0.0085, Acc=99.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 0.0179, Train Acc: 0.9950\n",
      "  Val Loss: 0.0085, Val Acc: 0.9976\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n",
      "Very low validation loss - possible data leakage!\n",
      "New best validation accuracy: 0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|█| 625/625 [08:39<00:00,  1.20it/s, Loss=0.0138, Acc=99\n",
      "Epoch 7/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.63it/s, Loss=0.0039, Acc=99.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 0.0138, Train Acc: 0.9952\n",
      "  Val Loss: 0.0039, Val Acc: 0.9990\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n",
      "Very low validation loss - possible data leakage!\n",
      "New best validation accuracy: 0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|█| 625/625 [08:39<00:00,  1.20it/s, Loss=0.0132, Acc=99\n",
      "Epoch 8/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.62it/s, Loss=0.0103, Acc=99.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 0.0132, Train Acc: 0.9959\n",
      "  Val Loss: 0.0103, Val Acc: 0.9968\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|█| 625/625 [08:43<00:00,  1.19it/s, Loss=0.0127, Acc=99\n",
      "Epoch 9/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.63it/s, Loss=0.0040, Acc=99.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 0.0127, Train Acc: 0.9965\n",
      "  Val Loss: 0.0040, Val Acc: 0.9988\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n",
      "Very low validation loss - possible data leakage!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|█| 625/625 [08:44<00:00,  1.19it/s, Loss=0.0110, Acc=9\n",
      "Epoch 10/10 [Val]: 100%|█| 157/157 [00:59<00:00,  2.63it/s, Loss=0.0078, Acc=99.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 0.0110, Train Acc: 0.9968\n",
      "  Val Loss: 0.0078, Val Acc: 0.9968\n",
      "  Learning Rate: 1.00e-04\n",
      "Very high validation accuracy - possible overfitting!\n",
      "Very low validation loss - possible data leakage!\n",
      "Loaded best model with validation accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/ResNet50_model.pth'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Starting ResNet Training...\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class_names = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\n",
    "\n",
    "resnet_model = ResNetModel(num_classes=5, pretrained=True).to(device)\n",
    "\n",
    "resnet_history = train_model(\n",
    "    model=resnet_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    patience=7\n",
    ")\n",
    "\n",
    "save_model(resnet_model, resnet_history, \"ResNet50\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cccb9764-56c6-4ed1-878f-fb33ccfbbf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ResNet50_model.pth']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb88c81-4a71-48a4-8a39-abc73ffa42a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'git' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgit\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'git' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213c2ac-0f76-443f-ab68-6d544f71dcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
